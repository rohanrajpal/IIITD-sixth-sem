{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3-Full.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzjIL803p97j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_PATH = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/dlassignment1/q3\"\n",
        "# !git clone \"https://85869b109f25ac5241470005fcd8ead1673b1329@github.com/rohanrajpal/dlassignment1.git\"\n",
        "\n",
        "!git config --global user.email \"rohan17089@iiitd.ac.in\"\n",
        "!git config --global user.name \"Rohan Rajpal\"\n",
        "\n",
        "%load_ext autoreload\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE-neHqsthjR",
        "colab_type": "text"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m5a10pstfE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "\n",
        "from retinanet import model\n",
        "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n",
        "    Normalizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from retinanet import coco_eval\n",
        "from retinanet import csv_eval\n",
        "from matplotlib import pyplot as plt\n",
        "import csv, json\n",
        "import os\n",
        "import pandas as pd\n",
        "from numpy.random import RandomState"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYztzl-Jtp-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_DATASET = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/assignment-data\"\n",
        "PATH_TO_WEIGHTS = PATH_TO_DATASET + \"/pretrained_weights_cleaned.pt\"\n",
        "ANNOTATION_CSV =\"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/assignment-data/annotations/instances_train_csv.csv\"\n",
        "CLASS_LIST =\"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/assignment-data/annotations/class_list.csv\"\n",
        "\n",
        "IMAGE_PATH = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/assignment-data/images/train\"\n",
        "INSTANCES_TRAIN_PATH = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/assignment-data/annotations/instances_train.json\"\n",
        "INSTANCES_TRAIN_ALT_PATH = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/assignment-data/annotations/instances_train_alt.json\"\n",
        "\n",
        "TRAIN_CSV = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/assignment-data/annotations/train.csv\"\n",
        "VAL_CSV = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/assignment-data/annotations/val.csv\"\n",
        "PATH_TO_FINETUNED_WEIGHTS = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/dlassignment1/q3/freeze_model/model_final.pt\"\n",
        "BEST_WEIGHTS = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/dlassignment1/q3/freeze_model/csv_retinanet_best_model.pt\"\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/assignment-data/data/\"\n",
        "\n",
        "annotations_json_path = data_dir + \"train_annotations.json\"\n",
        "annotations_csv_path = data_dir + \"train_annotations_csv.csv\"\n",
        "\n",
        "val_csv = annotations_csv_path\n",
        "train_csv = data_dir + \"train.csv\"\n",
        "\n",
        "\n",
        "weights_path = data_dir + \"pretrained_weights.pt\"\n",
        "images_path = data_dir + \"train\"\n",
        "# os.system(\"unzip -q \\\"{}\\\" -d \\\"{}\\\"\".format(images_path,data_dir))\n",
        "\n",
        "best_model_path = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/dlassignment1/q3/freeze_model/third/csv_retinanet_best_model_mAP.pt\"\n",
        "class_list = data_dir + \"class_list.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqLldN-5uc5h",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4MRcwJMufiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean the json\n",
        "with open(annotations_json_path) as f:\n",
        "  annot_json = json.load(f)\n",
        "\n",
        "annot_json_cleaned = {}\n",
        "\n",
        "annot_json_cleaned[\"info\"] = annot_json[\"info\"]\n",
        "annot_json_cleaned[\"categories\"] = annot_json[\"categories\"]\n",
        "annot_json_cleaned[\"images\"] = []\n",
        "annot_json_cleaned[\"annotations\"] = []\n",
        "\n",
        "file_path = {}\n",
        "for path, subdirs, files in os.walk(images_path):\n",
        "    if files:\n",
        "        # print(os.path.join(path, min(files)))\n",
        "        for file in files:\n",
        "          # print(file)\n",
        "          file_path[file] = os.path.join(path, file)\n",
        "\n",
        "def inFolder(elem):\n",
        "  if elem in file_path:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "# remove images which arent there\n",
        "for elem in annot_json[\"images\"]:\n",
        "  if inFolder(elem[\"file_name\"]):\n",
        "    annot_json_cleaned[\"images\"].append(elem)\n",
        "\n",
        "for elem in annot_json[\"annotations\"]:\n",
        "  if inFolder(elem[\"image_id\"]+\".jpg\"):\n",
        "    annot_json_cleaned[\"annotations\"].append(elem)\n",
        "\n",
        "annot_json = annot_json_cleaned\n",
        "\n",
        "print(\"JSON cleaned\")\n",
        "\n",
        "# Generate class list\n",
        "f_csv = open(class_list, 'w', newline='')\n",
        "\n",
        "writer = csv.writer(f_csv)\n",
        "lines = [\n",
        "[\"bird\",\"0\"],\n",
        "[\"bobcat\",\"1\"],\n",
        "[\"car\",\"2\"],\n",
        "[\"cat\",\"3\"],\n",
        "[\"raccoon\",\"4\"],\n",
        "[\"rabbit\",\"5\"],\n",
        "[\"coyote\",\"6\"],\n",
        "[\"squirrel\",\"7\"]\n",
        "]\n",
        "for line in lines:\n",
        "  writer.writerow(line)\n",
        "\n",
        "print(\"Made class list\")\n",
        "# Generate annotation CSV\n",
        "class_map = {\n",
        "11:\"bird\",\n",
        "6:\"bobcat\",\n",
        "33:\"car\",\n",
        "16:\"cat\",\n",
        "3:\"raccoon\",\n",
        "10:\"rabbit\",\n",
        "9:\"coyote\",\n",
        "5:\"squirrel\"\n",
        "}\n",
        "\n",
        "f_csv = open(annotations_csv_path, 'w', newline='')\n",
        "writer = csv.writer(f_csv)\n",
        "\n",
        "for anno in annot_json[\"annotations\"]:\n",
        "  bbox = [int(x) for x in anno[\"bbox\"]]\n",
        "  bbox[2] = bbox[0] + bbox[2]\n",
        "  bbox[3] = bbox[1] + bbox[3]\n",
        "  if(anno[\"category_id\"] in class_map):\n",
        "    class_name = class_map[anno[\"category_id\"]]\n",
        "    img_path = images_path +\"/\"+class_name+\"/\" +anno[\"image_id\"] + \".jpg\"\n",
        "    # print(img_path)\n",
        "    writer.writerow([img_path,bbox[0],bbox[1],bbox[2],bbox[3],class_name])\n",
        "\n",
        "print(\"Made annot CSV\")\n",
        "\n",
        "# Train-Val split\n",
        "df = pd.read_csv(annotations_csv_path,header=None)\n",
        "rng = RandomState()\n",
        "\n",
        "train = df.sample(frac=0.7, random_state=rng)\n",
        "test = df.loc[~df.index.isin(train.index)]\n",
        "\n",
        "# Make sure you do a good shuffle in csv\n",
        "train = train.iloc[np.random.permutation(len(train))]\n",
        "test = test.iloc[np.random.permutation(len(test))]\n",
        "\n",
        "train.to_csv(train_csv,index=False,header=None)\n",
        "test.to_csv(val_csv,index=False,header=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4puOhl-tOCq",
        "colab_type": "text"
      },
      "source": [
        "# Part 1 : Without finetuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM2UEcl7tbVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load val dataset\n",
        "dataset_val = CSVDataset(train_file = val_csv, class_list=class_list,\n",
        "                                    transform=transforms.Compose([Normalizer(),Resizer()]))\n",
        "print(\"Loaded val dataset\")\n",
        "# Eval karo\n",
        "use_gpu = True\n",
        "\n",
        "if use_gpu:\n",
        "    retinanet = retinanet.cuda()\n",
        "retinanet = torch.nn.DataParallel(retinanet).cuda()\n",
        "\n",
        "retinanet.training = False\n",
        "retinanet.eval()\n",
        "retinanet.module.freeze_bn()\n",
        "\n",
        "mAP = csv_eval.evaluate(dataset_val, retinanet)\n",
        "\n",
        "def avg(mAP):\n",
        "  avg_map = 0\n",
        "  for key in mAP:\n",
        "    avg_map += mAP[key][0]\n",
        "  avg_map /= 8\n",
        "\n",
        "  print(\"Avg mAP\",avg_map)\n",
        "\n",
        "  return avg_map\n",
        "print(avg(mAP))\n",
        "print(mAP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX2Wh7ubv3PR",
        "colab_type": "text"
      },
      "source": [
        "# Part 2 : With Finetuning and Loss Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfmf0LNjvyaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "BEST_WEIGHTS = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/dlassignment1/q3/freeze_model/csv_retinanet_best_model.pt\"\n",
        "\n",
        "parser = {\"csv_classes\":CLASS_LIST, \"csv_val\":VAL_CSV, \"csv_train\":TRAIN_CSV, \"epochs\":10 }\n",
        "\n",
        "dataset_train = CSVDataset(train_file=parser[\"csv_train\"], class_list=parser[\"csv_classes\"],\n",
        "                                   transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
        "dataset_val = CSVDataset(train_file=parser[\"csv_val\"], class_list=parser[\"csv_classes\"],\n",
        "                                     transform=transforms.Compose([Normalizer(), Resizer()]))\n",
        "\n",
        "sampler = AspectRatioBasedSampler(dataset_train, batch_size=2, drop_last=False)\n",
        "dataloader_train = DataLoader(dataset_train, num_workers=3, collate_fn=collater, batch_sampler=sampler)\n",
        "\n",
        "sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=1, drop_last=False)\n",
        "dataloader_val = DataLoader(dataset_val, num_workers=3, collate_fn=collater, batch_sampler=sampler_val)\n",
        "\n",
        "retinanet = model.resnet50(num_classes=dataset_train.num_classes(),)\n",
        "\n",
        "# for param in retinanet.parameters():\n",
        "#     param.requires_grad = False\n",
        "# for param in retinanet.classificationModel.output.parameters():\n",
        "#     param.requires_grad = True\n",
        "# for param in retinanet.regressionModel.output.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "use_gpu = True\n",
        "\n",
        "if use_gpu:\n",
        "    retinanet = retinanet.cuda()\n",
        "\n",
        "PATH_TO_DATASET = \"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/assignment-data\"\n",
        "PATH_TO_WEIGHTS = PATH_TO_DATASET + \"/pretrained_weights_cleaned.pt\"\n",
        "\n",
        "retinanet.load_state_dict(torch.load(PATH_TO_WEIGHTS))\n",
        "# retinanet = torch.load(BEST_WEIGHTS)\n",
        "\n",
        "retinanet = torch.nn.DataParallel(retinanet).cuda()\n",
        "\n",
        "retinanet.training = True\n",
        "\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, retinanet.parameters()), lr=1e-5)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
        "\n",
        "loss_hist = collections.deque(maxlen=500)\n",
        "\n",
        "loss_all_epochs = []\n",
        "map_all_epochs = []\n",
        "\n",
        "def avg(mAP):\n",
        "  avg_map = 0\n",
        "  for key in mAP:\n",
        "    avg_map += mAP[key][0]\n",
        "  avg_map /= 8\n",
        "\n",
        "  print(\"Avg mAP\",avg_map)\n",
        "\n",
        "  return avg_map\n",
        "\n",
        "\n",
        "retinanet.train()\n",
        "retinanet.module.freeze_bn()\n",
        "file1 = open(\"logfreezefour.txt\",\"w\")\n",
        "print('Num training images: {}'.format(len(dataset_train)))\n",
        "\n",
        "best_loss = 100\n",
        "best_map = 0\n",
        "for epoch_num in range(parser[\"epochs\"]):\n",
        "    print(\"\\nEpoch\",epoch_num)\n",
        "    retinanet.train()\n",
        "    retinanet.module.freeze_bn()\n",
        "\n",
        "    # if epoch_num == 10:\n",
        "    #   for param in retinanet.parameters():\n",
        "    #     param.requires_grad = True\n",
        "    #   optimizer = optim.Adam(filter(lambda p: p.requires_grad, retinanet.parameters()), lr=1e-5)\n",
        "    \n",
        "    # if epoch_num == 10:\n",
        "    #   for param in retinanet.parameters():\n",
        "    #       param.requires_grad = False\n",
        "    #   for param in retinanet.classificationModel.output.parameters():\n",
        "    #       param.requires_grad = True\n",
        "    #   for param in retinanet.regressionModel.output.parameters():\n",
        "    #       param.requires_grad = True\n",
        "    #   optimizer = optim.Adam(filter(lambda p: p.requires_grad, retinanet.parameters()), lr=1e-5)\n",
        "\n",
        "    epoch_loss = []\n",
        "\n",
        "    for iter_num, data in enumerate(dataloader_train):\n",
        "        try:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot']])\n",
        "\n",
        "            classification_loss = classification_loss.mean()\n",
        "            regression_loss = regression_loss.mean()\n",
        "\n",
        "            loss = classification_loss + regression_loss\n",
        "\n",
        "            if bool(loss == 0):\n",
        "                continue\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_hist.append(float(loss))\n",
        "\n",
        "            epoch_loss.append(float(loss))\n",
        "\n",
        "            # print(\n",
        "            #     'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n",
        "            #         epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist)))\n",
        "            \n",
        "            file1.write('Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f} \\n'.format(\n",
        "                    epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist)))\n",
        "            \n",
        "            del classification_loss\n",
        "            del regression_loss\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "\n",
        "    print('Evaluating dataset')\n",
        "\n",
        "    mAP = csv_eval.evaluate(dataset_val, retinanet)\n",
        "    avg_mAP = avg(mAP)\n",
        "    map_all_epochs.append(avg_mAP)\n",
        "\n",
        "    mean_loss = np.mean(epoch_loss)\n",
        "\n",
        "    scheduler.step(mean_loss)\n",
        "\n",
        "    loss_all_epochs.append(mean_loss)\n",
        "\n",
        "\n",
        "    if(mean_loss < best_loss):\n",
        "        torch.save(retinanet.module, 'freeze_model/fourth/{}_retinanet_{}.pt'.format(\"csv\", \"best_model_loss\"))\n",
        "        best_loss = mean_loss\n",
        "    \n",
        "    if(avg_mAP > best_map):\n",
        "      torch.save(retinanet.module, 'freeze_model/fourth/{}_retinanet_{}.pt'.format(\"csv\", \"best_model_mAP\"))\n",
        "      best_map = avg_mAP\n",
        "    \n",
        "    torch.save(retinanet.module, 'freeze_model/fourth/{}_retinanet_{}.pt'.format(\"csv\", epoch_num))\n",
        "    print(\"Best loss:\",best_loss,\"Best mAP:\",best_map)\n",
        "\n",
        "retinanet.eval()\n",
        "file1.close()\n",
        "torch.save(retinanet, 'freeze_model/fourth/model_final.pt')\n",
        "\n",
        "print(\"Loss curve\")\n",
        "x_axis = [x for x in range(parser[\"epochs\"])]\n",
        "plt.plot(x_axis,loss_all_epochs)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Running Loss\")\n",
        "plt.savefig(\"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/dlassignment1/q3/freeze_model/fourth/losscurve.png\")\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"mAP\")\n",
        "plt.plot(x_axis,map_all_epochs)\n",
        "plt.savefig(\"/content/drive/My Drive/Deep_Learning_Assignments/Assignment1/Q3/dlassignment1/q3/freeze_model/fourth/mapcurve.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnBrTHar_L_s",
        "colab_type": "text"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-KOm13v_OPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_caption(image, box, caption):\n",
        "  b = np.array(box).astype(int)\n",
        "  cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
        "  cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxq5ncP-_JTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = {\"csv_classes\":CLASS_LIST, \"csv_val\":VAL_CSV, \"model_finetuned\":BEST_WEIGHTS, \"model_raw\": PATH_TO_WEIGHTS}\n",
        "dataset_val = CSVDataset(train_file=parser[\"csv_val\"], class_list=parser[\"csv_classes\"], transform=transforms.Compose([Normalizer(), Resizer()]))\n",
        "\n",
        "sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=1, drop_last=False)\n",
        "dataloader_val = DataLoader(dataset_val, num_workers=1, collate_fn=collater, batch_sampler=sampler_val)\n",
        "\n",
        "retinanet_raw = model.resnet50(num_classes=8)\n",
        "\n",
        "retinanet_raw.load_state_dict(torch.load(parser[\"model_raw\"]))\n",
        "retinanet_finetuned = torch.load(parser[\"model_finetuned\"])\n",
        "torch.save(retinanet_finetuned.state_dict(), TO_SAVE_WT)\n",
        "\n",
        "\n",
        "def get_bbox(retinanet,img,bcolor,data,caption):\n",
        "  scores, classification, transformed_anchors = retinanet(data['img'].cuda().float())\n",
        "  # print(\"--------Classification-----------\")\n",
        "  # print(classification.shape,classification)\n",
        "  # print(\"--------Scores----------\")\n",
        "  # print(scores.shape,scores)\n",
        "  # print(\"---------Transformed_Idxs-------\")\n",
        "  # print(transformed_anchors.shape, transformed_anchors)\n",
        "  idxs = np.where(scores.cpu()>0.5)\n",
        "  # print(idxs[0])\n",
        "  # bbox = transformed_anchors[idxs[0][j], :]\n",
        "  class_labels = []\n",
        "  for j in range(idxs[0].shape[0]):\n",
        "      bbox = transformed_anchors[idxs[0][j], :]\n",
        "      x1 = int(bbox[0])\n",
        "      y1 = int(bbox[1])\n",
        "      x2 = int(bbox[2])\n",
        "      y2 = int(bbox[3])\n",
        "      label_name = dataset_val.labels[int(classification[idxs[0][j]])]\n",
        "      draw_caption(img, (x1, y1, x2, y2), label_name)\n",
        "      class_labels.append(label_name)\n",
        "      cv2.rectangle(img, (x1, y1), (x2, y2), color=bcolor, thickness=2)\n",
        "      # print(caption,label_name)\n",
        "  return class_labels\n",
        "\n",
        "\n",
        "def equalize(pred, truth):\n",
        "  diff = len(pred) - len(truth)\n",
        "  nothing_pad = [\"nothing\" for x in range(abs(diff))]\n",
        "  if(diff > 0):\n",
        "    truth += nothing_pad\n",
        "  elif(diff < 0):\n",
        "    pred += nothing_pad\n",
        "  return pred, truth\n",
        "  \n",
        "use_gpu = True\n",
        "\n",
        "if use_gpu:\n",
        "  retinanet_raw = retinanet_raw.cuda()\n",
        "  retinanet_finetuned = retinanet_finetuned.cuda()\n",
        "\n",
        "retinanet_raw.eval()\n",
        "retinanet_finetuned.eval()\n",
        "\n",
        "unnormalize = UnNormalizer()\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(20, 10))\n",
        "classcnt = [3 for x in range(8)]\n",
        "sum = 24\n",
        "\n",
        "\n",
        "raw_pred_list = []\n",
        "finetune_pred_list = []\n",
        "gt_raw_list = []\n",
        "gt_finetune_list = []\n",
        "cnt = 1 \n",
        "for idx, data in enumerate(dataloader_val):\n",
        "  # print(int(data['annot'][0][0][4]))\n",
        "\n",
        "  # 3 images for each class\n",
        "  # category = int(data['annot'][0][0][4])\n",
        "  # if(classcnt[category] > 0):\n",
        "  #   classcnt[category] -= 1\n",
        "  #   sum -= 1\n",
        "  # elif sum <= 0:\n",
        "  #   break\n",
        "  # else:\n",
        "  #   continue\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    \n",
        "    img = np.array(255 * unnormalize(data['img'][0, :, :, :])).copy()\n",
        "\n",
        "    img[img<0] = 0\n",
        "    img[img>255] = 255\n",
        "\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "    img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # st = time.time()\n",
        "    raw_pred = get_bbox(retinanet_raw,img,(0,0,255),data,str(cnt)+\" Model:\")\n",
        "    finetune_pred = get_bbox(retinanet_finetuned,img,(0,255,0),data,str(cnt)+\" Finetuned model:\")\n",
        "    gt_raw = []\n",
        "    gt_finetune = []\n",
        "    # Ground truth\n",
        "    # print(data['annot'])\n",
        "\n",
        "    for bbox in data['annot'][0]:\n",
        "      x1 = int(bbox[0])\n",
        "      y1 = int(bbox[1])\n",
        "      x2 = int(bbox[2])\n",
        "      y2 = int(bbox[3])\n",
        "      label_name = dataset_val.labels[int(bbox[4])]\n",
        "      gt_raw.append(label_name)\n",
        "      gt_finetune.append(label_name)\n",
        "      draw_caption(img, (x1, y1, x2, y2), label_name)\n",
        "      # print(str(cnt)+\" Ground truth:\",label_name)\n",
        "      cv2.rectangle(img, (x1, y1), (x2, y2), color=(255,0,0), thickness=2)\n",
        "      # print(label_name)\n",
        "\n",
        "    raw_pred,gt_raw = equalize(raw_pred,gt_raw)\n",
        "    finetune_pred,gt_finetune = equalize(finetune_pred,gt_finetune)\n",
        "\n",
        "    # print(\"Raw pretrained\",raw_pred,\"Ground\",gt_raw)\n",
        "    # print(\"Finetune pred\",finetune_pred,\"Ground\",gt_finetune)\n",
        "\n",
        "    raw_pred_list += raw_pred\n",
        "    finetune_pred_list += finetune_pred\n",
        "\n",
        "    gt_raw_list += gt_raw\n",
        "    gt_finetune_list += gt_finetune\n",
        "\n",
        "    # print(\"Ground truth\",gt)\n",
        "    # print(\"------------------------\")\n",
        "    # print('Elapsed time: {}'.format(time.time()-st))\n",
        "\n",
        "    # plt.figure(figsize=(20,10)) \n",
        "    # plt.imshow(img)\n",
        "    # plt.savefig(\"images1/\"+str(cnt)+\"classification.png\")\n",
        "    # print(\"---------------------------------\")\n",
        "    cnt += 1\n",
        "    # plt.show()\n",
        "\n",
        "# print(len(raw_pred_list),len(gt_raw_list))\n",
        "# print(len(finetune_pred_list),len(gt_finetune_list))\n",
        "\n",
        "# print((raw_pred_list),(gt_raw_list))\n",
        "# print((finetune_pred_list),(gt_finetune_list))\n",
        "\n",
        "print(confusion_matrix(gt_raw_list,raw_pred_list,labels=[\"bird\",\"bobcat\",\"car\",\"cat\",\"raccoon\",\"rabbit\",\"coyote\",\"squirrel\",\"nothing\"]))\n",
        "print(confusion_matrix(gt_finetune_list,finetune_pred_list,labels=[\"bird\",\"bobcat\",\"car\",\"cat\",\"raccoon\",\"rabbit\",\"coyote\",\"squirrel\",\"nothing\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I3Bwq62-1H5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = {\"csv_classes\":CLASS_LIST, \"csv_val\":VAL_CSV, \"model_finetuned\":BEST_WEIGHTS, \"model_raw\": PATH_TO_WEIGHTS}\n",
        "dataset_val = CSVDataset(train_file=parser[\"csv_val\"], class_list=parser[\"csv_classes\"], transform=transforms.Compose([Normalizer(), Resizer()]))\n",
        "\n",
        "sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=1, drop_last=False)\n",
        "dataloader_val = DataLoader(dataset_val, num_workers=1, collate_fn=collater, batch_sampler=sampler_val)\n",
        "\n",
        "retinanet_raw = model.resnet50(num_classes=8)\n",
        "\n",
        "retinanet_raw.load_state_dict(torch.load(parser[\"model_raw\"]))\n",
        "retinanet_finetuned = torch.load(parser[\"model_finetuned\"])\n",
        "torch.save(retinanet_finetuned.state_dict(), TO_SAVE_WT)\n",
        "\n",
        "\n",
        "def get_bbox(retinanet,img,bcolor,data,caption):\n",
        "  scores, classification, transformed_anchors = retinanet(data['img'].cuda().float())\n",
        "  # print(\"--------Classification-----------\")\n",
        "  # print(classification.shape,classification)\n",
        "  # print(\"--------Scores----------\")\n",
        "  # print(scores.shape,scores)\n",
        "  # print(\"---------Transformed_Idxs-------\")\n",
        "  # print(transformed_anchors.shape, transformed_anchors)\n",
        "  idxs = np.where(scores.cpu()>0.5)\n",
        "  # print(idxs[0])\n",
        "  # bbox = transformed_anchors[idxs[0][j], :]\n",
        "  class_labels = []\n",
        "  for j in range(idxs[0].shape[0]):\n",
        "      bbox = transformed_anchors[idxs[0][j], :]\n",
        "      x1 = int(bbox[0])\n",
        "      y1 = int(bbox[1])\n",
        "      x2 = int(bbox[2])\n",
        "      y2 = int(bbox[3])\n",
        "      label_name = dataset_val.labels[int(classification[idxs[0][j]])]\n",
        "      draw_caption(img, (x1, y1, x2, y2), label_name)\n",
        "      class_labels.append(label_name)\n",
        "      cv2.rectangle(img, (x1, y1), (x2, y2), color=bcolor, thickness=2)\n",
        "      # print(caption,label_name)\n",
        "  return class_labels\n",
        "\n",
        "\n",
        "def equalize(pred, truth):\n",
        "  diff = len(pred) - len(truth)\n",
        "  nothing_pad = [\"nothing\" for x in range(abs(diff))]\n",
        "  if(diff > 0):\n",
        "    truth += nothing_pad\n",
        "  elif(diff < 0):\n",
        "    pred += nothing_pad\n",
        "  return pred, truth\n",
        "  \n",
        "use_gpu = True\n",
        "\n",
        "if use_gpu:\n",
        "  retinanet_raw = retinanet_raw.cuda()\n",
        "  retinanet_finetuned = retinanet_finetuned.cuda()\n",
        "\n",
        "retinanet_raw.eval()\n",
        "retinanet_finetuned.eval()\n",
        "\n",
        "unnormalize = UnNormalizer()\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(20, 10))\n",
        "classcnt = [3 for x in range(8)]\n",
        "sum = 24\n",
        "\n",
        "\n",
        "raw_pred_list = []\n",
        "finetune_pred_list = []\n",
        "gt_raw_list = []\n",
        "gt_finetune_list = []\n",
        "cnt = 1 \n",
        "for idx, data in enumerate(dataloader_val):\n",
        "  # print(int(data['annot'][0][0][4]))\n",
        "\n",
        "  # 3 images for each class\n",
        "  category = int(data['annot'][0][0][4])\n",
        "  if(classcnt[category] > 0):\n",
        "    classcnt[category] -= 1\n",
        "    sum -= 1\n",
        "  elif sum <= 0:\n",
        "    break\n",
        "  else:\n",
        "    continue\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    \n",
        "    img = np.array(255 * unnormalize(data['img'][0, :, :, :])).copy()\n",
        "\n",
        "    img[img<0] = 0\n",
        "    img[img>255] = 255\n",
        "\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "    img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # st = time.time()\n",
        "    raw_pred = get_bbox(retinanet_raw,img,(0,0,255),data,str(cnt)+\" Model:\")\n",
        "    finetune_pred = get_bbox(retinanet_finetuned,img,(0,255,0),data,str(cnt)+\" Finetuned model:\")\n",
        "    gt_raw = []\n",
        "    gt_finetune = []\n",
        "    # Ground truth\n",
        "    # print(data['annot'])\n",
        "\n",
        "    for bbox in data['annot'][0]:\n",
        "      x1 = int(bbox[0])\n",
        "      y1 = int(bbox[1])\n",
        "      x2 = int(bbox[2])\n",
        "      y2 = int(bbox[3])\n",
        "      label_name = dataset_val.labels[int(bbox[4])]\n",
        "      gt_raw.append(label_name)\n",
        "      gt_finetune.append(label_name)\n",
        "      draw_caption(img, (x1, y1, x2, y2), label_name)\n",
        "      # print(str(cnt)+\" Ground truth:\",label_name)\n",
        "      cv2.rectangle(img, (x1, y1), (x2, y2), color=(255,0,0), thickness=2)\n",
        "      # print(label_name)\n",
        "\n",
        "    raw_pred,gt_raw = equalize(raw_pred,gt_raw)\n",
        "    finetune_pred,gt_finetune = equalize(finetune_pred,gt_finetune)\n",
        "\n",
        "    # print(\"Raw pretrained\",raw_pred,\"Ground\",gt_raw)\n",
        "    # print(\"Finetune pred\",finetune_pred,\"Ground\",gt_finetune)\n",
        "\n",
        "    raw_pred_list += raw_pred\n",
        "    finetune_pred_list += finetune_pred\n",
        "\n",
        "    gt_raw_list += gt_raw\n",
        "    gt_finetune_list += gt_finetune\n",
        "\n",
        "    # print(\"Ground truth\",gt)\n",
        "    # print(\"------------------------\")\n",
        "    # print('Elapsed time: {}'.format(time.time()-st))\n",
        "\n",
        "    # plt.figure(figsize=(20,10)) \n",
        "    plt.imshow(img)\n",
        "    # plt.savefig(\"images1/\"+str(cnt)+\"classification.png\")\n",
        "    print(\"---------------------------------\")\n",
        "    cnt += 1\n",
        "    plt.show()\n",
        "\n",
        "# print(len(raw_pred_list),len(gt_raw_list))\n",
        "# print(len(finetune_pred_list),len(gt_finetune_list))\n",
        "\n",
        "# print((raw_pred_list),(gt_raw_list))\n",
        "# print((finetune_pred_list),(gt_finetune_list))\n",
        "\n",
        "print(confusion_matrix(gt_raw_list,raw_pred_list,labels=[\"bird\",\"bobcat\",\"car\",\"cat\",\"raccoon\",\"rabbit\",\"coyote\",\"squirrel\",\"nothing\"]))\n",
        "print(confusion_matrix(gt_finetune_list,finetune_pred_list,labels=[\"bird\",\"bobcat\",\"car\",\"cat\",\"raccoon\",\"rabbit\",\"coyote\",\"squirrel\",\"nothing\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}